# ğŸŒ Intelligence at the Edge: IoT Data Aggregation & Processing Gateway

> **A robust edge computing gateway built on Raspberry Pi using Go**  
> This project implements intelligent, resilient data preprocessing at the network edge, reducing bandwidth, improving data quality, and enabling reliable telemetry flow from IoT sensors to cloud analytics via Kafka.

---

## ğŸ” Project Overview

In modern IoT systems, sending raw sensor data directly to the cloud leads to **high bandwidth usage**, **latency bottlenecks**, and **increased operational costs**. This project solves that with an **intelligent edge gateway** running on a **Raspberry Pi**, written in **Go (Golang)** for performance, concurrency, and efficiency.

The gateway:
- ğŸ“¥ **Ingests** real-time sensor data via **MQTT**
- ğŸ’¾ **Buffers** data locally during network outages
- ğŸ§¹ **Filters, aggregates, and enriches** data at the edge
- ğŸš€ **Forwards cleansed, high-value data** to **Apache Kafka** for downstream analytics

By moving â€œintelligenceâ€ to the edge, this solution enables:
- âœ… Up to **98% reduction in data volume**
- âœ… **No data loss** during intermittent connectivity
- âœ… **Low-latency local processing**
- âœ… **Scalable integration** with real-time analytics, data lakes, or ML pipelines

Perfect for **industrial monitoring**, **smart environment systems**, or **remote sensing infrastructures**.

---

## ğŸ§© Key Features

âœ… **MQTT Subscriber** â€“ Real-time ingestion from IoT sensors using topics like `sensors/+/data`  
âœ… **Resilient Local Buffering** â€“ Disk-persistent SQLite queue ensures data survival during outages  
âœ… **Configurable Data Processing** â€“ Filter noise, aggregate values (e.g., avg temp per minute), enrich with metadata  
âœ… **Kafka Producer Integration** â€“ Reliable delivery to centralized Kafka cluster using `confluent-kafka-go`  
âœ… **Fault-Tolerant Design** â€“ Exponential backoff retry, automatic reconnection, message deduplication  
âœ… **Lightweight & Efficient** â€“ Built in Go: one static binary, minimal CPU/memory footprint  
âœ… **YAML Configuration** â€“ Human-readable, easily modifiable rules for topics, filters, thresholds, and intervals  
âœ… **Structured Logging** â€“ Logging with Zap for debugging and operations

---

## ğŸ—ï¸ System Architecture

This gateway sits between local IoT devices and a centralized analytics backend:

```mermaid
graph LR
    subgraph Edge Site
        A[IoT Sensor Devices] --> M[(MQTT Broker)]
        M --> G[Edge Gateway<br><small>Raspberry Pi + Go App</small>]
        style G fill:#4CAF50,stroke:#388E3C,color:#fff
    end

    subgraph Central / Cloud
        G -- "Kafka Producer" --> K[(Kafka Cluster)]
        K --> D[Data Lake / DB]
        K --> E[Analytics / ML]
        K --> F[Dashboards]
        style K fill:#2C2C2C,stroke:#FFF,stroke-width:2px,color:#fff
    end

    style M fill:#663366,stroke:#333,stroke-width:2px,color:#fff
    style A fill:#D0D0D0,stroke:#333,stroke-width:1px
    style D fill:#D0D0D0,stroke:#333,stroke-width:1px
    style E fill:#D0D0D0,stroke:#333,stroke-width:1px
    style F fill:#D0D0D0,stroke:#333,stroke-width:1px
```

### Why Edge Processing Matters

| Traditional Approach | âœ… This Gateway |
|----------------------|----------------|
| Sensors â†’ Raw Data â†’ Cloud â†’ Process | Sensors â†’ Clean/Agg Data â†’ Cloud â†’ Analytics |
| High bandwidth cost | Drastically reduced data flow |
| Sensitive to network issues | Local buffering ensures no data loss |
| Cloud bears full processing load | Edge handles filtering & aggregation |

Edge-first processing is **essential for scale, cost-efficiency, and reliability**.

---

## ğŸ› ï¸ Tech Stack

| Layer            | Technology                                   |
|------------------|----------------------------------------------|
| **Hardware**     | Raspberry Pi 4/5 (ARM64), or any Linux device |
| **Language**     | Go (Golang) 1.21+                             |
| **MQTT Client**  | Eclipse Paho Go MQTT                          |
| **Kafka Client** | Confluent Kafka Go (`confluent-kafka-go`)     |
| **Storage**      | SQLite (disk-backed buffering)                |
| **Config**       | YAML + Viper                                  |
| **Logging**      | Zap (structured, leveled logging)             |
| **Build Tool**   | Makefile + Go modules                         |
| **Deployment**   | systemd service (recommended), or `nohup`     |

![Go](https://img.shields.io/badge/Go-1.21+-00ADD8?style=for-the-badge&logo=go)  
![Raspberry Pi](https://img.shields.io/badge/Raspberry%20Pi-A22846?style=for-the-badge&logo=raspberrypi)  
![MQTT](https://img.shields.io/badge/MQTT-663366?style=for-the-badge&logo=mqtt)  
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=for-the-badge&logo=apachekafka)  
![License](https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge)

---

## ğŸš€ Getting Started

### Prerequisites

- âœ… Raspberry Pi (4 or 5 recommended) with Raspberry Pi OS Lite
- âœ… Go 1.21+ installed (`go version`)
- âœ… Local MQTT broker (e.g., Mosquitto)
- âœ… Access to Kafka cluster (local or remote)
- âœ… Basic Linux command-line skills

---

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/intelligence-at-the-edge.git
cd intelligence-at-the-edge
```

---

### 2. Install Dependencies

```bash
go mod tidy
```

---

### 3. Configure the Gateway

Edit `config/config.yaml` to match your environment:

```yaml
mqtt:
  broker: "tcp://192.168.1.100:1883"
  client_id: "edge-gateway-01"
  topic: "sensors/#"
  qos: 1

kafka:
  brokers:
    - "kafka1.internal:9092"
    - "kafka2.internal:9092"
  topic: "iot-sensor-data"
  client_id: "edge-producer"

buffer:
  path: "./data/buffer.db"
  max_size_mb: 100
  flush_interval_seconds: 30

processing:
  aggregation_window_seconds: 60
  rules:
    - type: "filter"
      field: "temperature"
      operator: "<"
      value: -50
      action: "drop"
    - type: "filter"
      field: "temperature"
      operator: ">"
      value: 100
      action: "drop"
    - type: "aggregate"
      field: "temperature"
      function: "average"
      output_name: "avg_temp"
    - type: "aggregate"
      field: "humidity"
      function: "avg"
      output_name: "avg_humidity"

logging:
  level: "info"
  output: "file"
  file: "./logs/gateway.log"
```

> ğŸ’¡ Tip: This config filters out physically impossible temperatures and emits one aggregated message per minute instead of raw per-second readings.

---

### 4. Build the Binary

```bash
make build
```

> If you donâ€™t have `make`, use:  
> `go build -o bin/edge-gateway cmd/gateway/main.go`

---

### 5. Run the Gateway

#### Option A: Manual Run (Testing)

```bash
./bin/edge-gateway --config config/config.yaml
```

Press `Ctrl+C` to stop.

#### Option B: Run as Systemd Service (Production)

```bash
sudo make install-service
sudo systemctl enable edge-gateway
sudo systemctl start edge-gateway
```

Check status:
```bash
sudo systemctl status edge-gateway
journalctl -u edge-gateway.service -f
```

---

### 6. Test the Data Flow

1. **Publish sample data to MQTT:**

```bash
mosquitto_pub -h 192.168.1.100 -t "sensors/device01/data" -m \
'{"temperature": 23.5, "humidity": 55, "timestamp": "2025-04-05T12:00:00Z"}'
```

2. **Monitor Kafka topic:**

```bash
kafka-console-consumer.sh --bootstrap-server kafka1:9092 \
--topic iot-sensor-data --from-beginning
```

You should see:
```json
{
  "location": "site-a",
  "avg_temp": 23.8,
  "avg_humidity": 57.2,
  "samples": 60,
  "window_start": "2025-04-05T12:00:00Z",
  "gateway_id": "edge-gateway-01"
}
```

---

## ğŸ“Š Impact: Data Volume Reduction

| Approach | Messages/Minute | Total over 24h |
|--------|------------------|----------------|
| Raw Data (Per Sensor) | 60 | 86,400 |
| **Edge-Aggregated** | **1** | **1,440** |
| âœ… **Reduction** |  | **~98%+** |

This directly reduces cloud costs, Kafka load, and network strain.

---

## ğŸ”„ Resilience & Fault Tolerance

The gateway ensures **zero data loss** under unstable conditions:

| Scenario | Behavior |
|--------|---------|
| Network Down | Data buffered in SQLite (`data/buffer.db`) |
| Kafka Unavailable | Retries with exponential backoff |
| Power Loss | SQLite persists; resumes after reboot |
| Message Duplication | Idempotent design avoids double-sends |

> âš ï¸ Never lose critical sensor telemetry again.

---

## ğŸ—‚ï¸ Repository Structure

```
intelligence-at-the-edge/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ gateway/
â”‚       â””â”€â”€ main.go                 # Entry point
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ mqtt/                       # Handles MQTT subscription
â”‚   â”œâ”€â”€ buffer/                     # SQLite queue with persistence
â”‚   â”œâ”€â”€ processor/                  # Filters, aggregates, enriches
â”‚   â”œâ”€â”€ kafka/                      # Kafka producer wrapper
â”‚   â”œâ”€â”€ config/                     # Viper-based config loader
â”‚   â””â”€â”€ logger/                     # Structured logging setup
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                 # Default config
â”œâ”€â”€ data/                           # (Gitignored) SQLite storage
â”œâ”€â”€ logs/                           # (Gitignored) Log files
â”œâ”€â”€ bin/                            # (Gitignored) Compiled binary
â”œâ”€â”€ Makefile                        # Build, run, deploy helpers
â”œâ”€â”€ go.mod
â”œâ”€â”€ go.sum
â””â”€â”€ README.md
```

---

## ğŸ§  Intelligent Data Processing

The `processor` package applies configurable rules:

```yaml
rules:
  - type: "filter"
    field: "quality_score"
    operator: "<"
    value: 0.7
    action: "drop"
  - type: "aggregate"
    field: "vibration"
    function: "avg"
    window_seconds: 60
```

Functions supported:
- **Filter**: Drop invalid or irrelevant data
- **Aggregate**: Avg / Sum / Min / Max over time window
- **Enrich**: Add gateway ID, site, timestamp, derived fields
- **Transform**: Convert units, standardize formats

---

## ğŸš§ Future Enhancements

- ğŸ”® **Edge AI/ML**: Run TinyML models for anomaly detection
- ğŸ–¥ï¸ **Local Dashboard**: Lightweight web UI using Gin or Echo
- ğŸŒ **Multi-Protocol Support**: Add CoAP, HTTP, or Modbus input
- ğŸ” **Security**: TLS, mTLS, JWT authentication for MQTT/Kafka
- ğŸ§¾ **OTA Configuration**: Dynamically update rules via MQTT command
- ğŸ“ˆ **Metrics Export**: Prometheus endpoint + Grafana dashboards

---

## ğŸ¤ Contributing

Contributions are **highly welcome**!

You can help by:
- âœ… Adding new processing rules (e.g., outlier detection)
- âœ… Improving error handling & observability
- âœ… Adding security features (TLS, auth)
- âœ… Writing integration tests
- âœ… Creating Docker/Podman support
- âœ… Building deployment scripts (Ansible, Terraform)

ğŸ‘‰ Open an issue or submit a PR!

---

## ğŸ“š Learning Outcomes

This project teaches advanced concepts in:
- ğŸ–¥ï¸ Concurrent programming with Go (goroutines, channels)
- ğŸ“¡ Event-driven architectures with MQTT
- ğŸ’¡ Stream processing and data aggregation
- ğŸ§± Data persistence on constrained edge devices
- ğŸ”„ Integration with Kafka for scalable data pipelines
- ğŸ”‹ System resilience patterns (buffering, retry, idempotency)
- ğŸ› ï¸ DevOps: logging, monitoring, deployment

Ideal for developers targeting roles in **IoT**, **cloud-native systems**, **data engineering**, or **edge AI**.

---

## ğŸ—ƒï¸ License

MIT License â€“ see [LICENSE](LICENSE) for details.
