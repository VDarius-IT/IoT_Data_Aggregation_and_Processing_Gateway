# ğŸŒ Intelligenz am Netzwerkrand (Edge): IoT Datenaggregations & Verarbeitungs-Gateway

> **Ein robustes Edge Computing-Gateway, entwickelt auf einem Raspberry Pi mit Go**  
> Dieses Projekt implementiert eine intelligente, resiliente Datenvorverarbeitung am Netzwerkrand, um Bandbreite zu reduzieren, die DatenqualitÃ¤t zu verbessern und einen zuverlÃ¤ssigen Telemetriefluss von IoT-Sensoren zu Cloud-Analysen Ã¼ber Kafka zu ermÃ¶glichen.

---

## ğŸ” ProjektÃ¼bersicht

In modernen IoT Systemen fÃ¼hrt das direkte Senden von Rohdaten von Sensoren in die Cloud zu **hoher Bandbreitennutzung**, **LatenzengpÃ¤ssen** und **erhÃ¶hten Betriebskosten**. Dieses Projekt lÃ¶st dieses Problem mit einem **intelligenten Edge-Gateway**, das auf einem **Raspberry Pi** lÃ¤uft und in **Go (Golang)** geschrieben ist, um hohe Leistung, ParallelitÃ¤t und Effizienz zu gewÃ¤hrleisten.

Das Gateway:
- ğŸ“¥ **Erfasst** Echtzeit-Sensordaten Ã¼ber **MQTT**
- ğŸ’¾ **Puffert** Daten lokal wÃ¤hrend NetzwerkausfÃ¤llen
- ğŸ§¹ **Filtert, aggregiert und reichert** Daten am Edge an
- ğŸš€ **Leitet bereinigte, hochwertige Daten** an **Apache Kafka** fÃ¼r nachgelagerte Analysen weiter

Indem die â€Intelligenzâ€œ an den Rand des Netzwerks verlagert wird, ermÃ¶glicht diese LÃ¶sung:
- âœ… Bis zu **98 % Reduzierung des Datenvolumens**
- âœ… **Kein Datenverlust** bei unterbrochener KonnektivitÃ¤t
- âœ… **Lokale Verarbeitung mit geringer Latenz**
- âœ… **Skalierbare Integration** mit Echtzeit Analysen, Data Lakes oder ML Pipelines

Perfekt fÃ¼r **industrielle Ãœberwachung**, **Smart Environment Systeme** oder **Fernerkundungsinfrastrukturen**.

---

## ğŸ§© Kernfunktionen

âœ… **MQTT-Subscriber** â€“ Echtzeit-Erfassung von IoT-Sensoren Ã¼ber Topics wie `sensors/+/data`  
âœ… **Resiliente lokale Pufferung** â€“ Eine festplattenbasierte SQLite-Warteschlange stellt die Datensicherheit bei AusfÃ¤llen sicher  
âœ… **Konfigurierbare Datenverarbeitung** â€“ Filtern von Rauschen, Aggregieren von Werten (z. B. durchschnittliche Temperatur pro Minute), Anreichern mit Metadaten  
âœ… **Kafka-Producer-Integration** â€“ ZuverlÃ¤ssige Zustellung an einen zentralen Kafka-Cluster mit `confluent-kafka-go`  
âœ… **Fehlertolerantes Design** â€“ Exponentielles Backoff bei Wiederholungsversuchen, automatische Wiederverbindung, Deduplizierung von Nachrichten  
âœ… **Leichtgewichtig & Effizient** â€“ In Go entwickelt: eine statische BinÃ¤rdatei, minimaler CPU-/Speicherverbrauch  
âœ… **YAML-Konfiguration** â€“ Menschenlesbare, leicht anpassbare Regeln fÃ¼r Topics, Filter, Schwellenwerte und Intervalle  
âœ… **Strukturiertes Logging** â€“ Protokollierung mit Zap fÃ¼r Debugging und Betrieb

---

## ğŸ—ï¸ Systemarchitektur

Dieses Gateway befindet sich zwischen lokalen IoT-GerÃ¤ten und einem zentralen Analyse-Backend:

```mermaid
graph LR
    subgraph Edge-Standort
        A[IoT-SensorgerÃ¤te] --> M[(MQTT-Broker)]
        M --> G[Edge-Gateway<br><small>Raspberry Pi + Go-Anwendung</small>]
        style G fill:#4CAF50,stroke:#388E3C,color:#fff
    end

    subgraph Zentrale / Cloud
        G -- "Kafka-Producer" --> K[(Kafka-Cluster)]
        K --> D[Data Lake / DB]
        K --> E[Analyse / ML]
        K --> F[Dashboards]
        style K fill:#2C2C2C,stroke:#FFF,stroke-width:2px,color:#fff
    end

    style M fill:#663366,stroke:#333,stroke-width:2px,color:#fff
    style A fill:#D0D0D0,stroke:#333,stroke-width:1px
    style D fill:#D0D0D0,stroke:#333,stroke-width:1px
    style E fill:#D0D0D0,stroke:#333,stroke-width:1px
    style F fill:#D0D0D0,stroke:#333,stroke-width:1px
```

### Warum Edge-Verarbeitung wichtig ist

| HerkÃ¶mmlicher Ansatz | âœ… Dieses Gateway |
|----------------------|----------------|
| Sensoren â†’ Rohdaten â†’ Cloud â†’ Verarbeitung | Sensoren â†’ Bereinigte/Aggregierte Daten â†’ Cloud â†’ Analyse |
| Hohe Bandbreitenkosten | Drastisch reduzierter Datenfluss |
| AnfÃ¤llig fÃ¼r Netzwerkprobleme | Lokale Pufferung sichert vor Datenverlust |
| Cloud trÃ¤gt die gesamte Verarbeitungslast | Edge Ã¼bernimmt Filterung & Aggregation |

Eine Edge-First-Verarbeitung ist **entscheidend fÃ¼r Skalierbarkeit, Kosteneffizienz und ZuverlÃ¤ssigkeit**.

---

## ğŸ› ï¸ Tech Stack

| Ebene            | Technologie                                  |
|------------------|----------------------------------------------|
| **Hardware**     | Raspberry Pi 4/5 (ARM64) oder jedes Linux GerÃ¤t |
| **Sprache**      | Go (Golang) 1.21+                             |
| **MQTT Client**  | Eclipse Paho Go MQTT                          |
| **Kafka Client** | Confluent Kafka Go (`confluent kafka go`)     |
| **Speicher**     | SQLite (festplattenbasierte Pufferung)        |
| **Konfiguration**| YAML + Viper                                  |
| **Logging**      | Zap (strukturiertes, levelbasiertes Logging)  |
| **Build Tool**   | Makefile + Go Module                          |
| **Deployment**   | systemd Dienst (empfohlen) oder `nohup`      |

![Go](https://img.shields.io/badge/Go-1.21+-00ADD8?style=for-the-badge&logo=go)  
![Raspberry Pi](https://img.shields.io/badge/Raspberry%20Pi-A22846?style=for-the-badge&logo=raspberrypi)  
![MQTT](https://img.shields.io/badge/MQTT-663366?style=for-the-badge&logo=mqtt)  
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?style=for-the-badge&logo=apachekafka)  
![Lizenz](https://img.shields.io/badge/Lizenz-MIT-blue.svg?style=for-the-badge)

---

## ğŸš€ Erste Schritte

### Voraussetzungen

- âœ… Raspberry Pi (4 oder 5 empfohlen) mit Raspberry Pi OS Lite
- âœ… Go 1.21+ installiert (`go version`)
- âœ… Lokaler MQTT-Broker (z. B. Mosquitto)
- âœ… Zugriff auf einen Kafka-Cluster (lokal oder remote)
- âœ… Grundlegende Linux-Kommandozeilenkenntnisse

---

### 1. Repository klonen

```bash
git clone https://github.com/your-username/intelligence-at-the-edge.git
cd intelligence-at-the-edge
```

---

### 2. AbhÃ¤ngigkeiten installieren

```bash
go mod tidy
```

---

### 3. Gateway konfigurieren

Bearbeiten Sie `config/config.yaml`, um sie an Ihre Umgebung anzupassen:

```yaml
mqtt:
  broker: "tcp://192.168.1.100:1883"
  client_id: "edge-gateway-01"
  topic: "sensors/#"
  qos: 1

kafka:
  brokers:
    - "kafka1.internal:9092"
    - "kafka2.internal:9092"
  topic: "iot-sensor-data"
  client_id: "edge-producer"

buffer:
  path: "./data/buffer.db"
  max_size_mb: 100
  flush_interval_seconds: 30

processing:
  aggregation_window_seconds: 60
  rules:
    - type: "filter"
      field: "temperature"
      operator: "<"
      value: -50
      action: "drop"
    - type: "filter"
      field: "temperature"
      operator: ">"
      value: 100
      action: "drop"
    - type: "aggregate"
      field: "temperature"
      function: "average"
      output_name: "avg_temp"
    - type: "aggregate"
      field: "humidity"
      function: "avg"
      output_name: "avg_humidity"

logging:
  level: "info"
  output: "file"
  file: "./logs/gateway.log"
```

> ğŸ’¡ Tipp: Diese Konfiguration filtert physikalisch unmÃ¶gliche Temperaturen heraus und sendet eine aggregierte Nachricht pro Minute anstelle von Rohdaten pro Sekunde.

---

### 4. BinÃ¤rdatei erstellen

```bash
make build
```

> Wenn Sie `make` nicht installiert haben, verwenden Sie:  
> `go build -o bin/edge-gateway cmd/gateway/main.go`

---

### 5. Gateway ausfÃ¼hren

#### Option A: Manueller Start (Testen)

```bash
./bin/edge-gateway --config config/config.yaml
```

DrÃ¼cken Sie `Ctrl+C` zum Beenden.

#### Option B: Als Systemd-Dienst ausfÃ¼hren (Produktion)

```bash
sudo make install-service
sudo systemctl enable edge-gateway
sudo systemctl start edge-gateway
```

Status Ã¼berprÃ¼fen:
```bash
sudo systemctl status edge-gateway
journalctl -u edge-gateway.service -f
```

---

### 6. Datenfluss testen

1. **Beispieldaten an MQTT senden:**

```bash
mosquitto_pub -h 192.168.1.100 -t "sensors/device01/data" -m \
'{"temperature": 23.5, "humidity": 55, "timestamp": "2025-04-05T12:00:00Z"}'
```

2. **Kafka-Topic Ã¼berwachen:**

```bash
kafka-console-consumer.sh --bootstrap-server kafka1:9092 \
--topic iot-sensor-data --from-beginning
```

Sie sollten Folgendes sehen:
```json
{
  "location": "site-a",
  "avg_temp": 23.8,
  "avg_humidity": 57.2,
  "samples": 60,
  "window_start": "2025-04-05T12:00:00Z",
  "gateway_id": "edge-gateway-01"
}
```

---

## ğŸ“Š Auswirkungen: Reduzierung des Datenvolumens

| Ansatz | Nachrichten/Minute | Gesamt Ã¼ber 24h |
|--------|------------------|----------------|
| Rohdaten (pro Sensor) | 60 | 86.400 |
| **Edge-aggregiert** | **1** | **1.440** |
| âœ… **Reduzierung** |  | **~98 %+** |

Dies reduziert direkt die Cloud-Kosten, die Kafka-Last und die Netzwerkbelastung.

---

## ğŸ”„ Resilienz & Fehlertoleranz

Das Gateway stellt **null Datenverlust** unter instabilen Bedingungen sicher:

| Szenario | Verhalten |
|--------|---------|
| Netzwerkausfall | Daten werden in SQLite gepuffert (`data/buffer.db`) |
| Kafka nicht verfÃ¼gbar | Wiederholungsversuche mit exponentiellem Backoff |
| Stromausfall | SQLite speichert persistent; Fortsetzung nach Neustart |
| Nachrichtenduplikate | Idempotentes Design vermeidet doppeltes Senden |

> âš ï¸ Verlieren Sie nie wieder kritische Sensortelemetrie.

---

## ğŸ—‚ï¸ Repository-Struktur

```
intelligence-at-the-edge/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ gateway/
â”‚       â””â”€â”€ main.go                 # Einstiegspunkt
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ mqtt/                       # Behandelt MQTT-Abonnements
â”‚   â”œâ”€â”€ buffer/                     # SQLite-Warteschlange mit Persistenz
â”‚   â”œâ”€â”€ processor/                  # Filtert, aggregiert, reichert an
â”‚   â”œâ”€â”€ kafka/                      # Wrapper fÃ¼r den Kafka-Producer
â”‚   â”œâ”€â”€ config/                     # Viper-basierter Konfigurationslader
â”‚   â””â”€â”€ logger/                     # Einrichtung fÃ¼r strukturiertes Logging
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                 # Standardkonfiguration
â”œâ”€â”€ data/                           # (In .gitignore) SQLite-Speicher
â”œâ”€â”€ logs/                           # (In .gitignore) Log-Dateien
â”œâ”€â”€ bin/                            # (In .gitignore) Kompilierte BinÃ¤rdatei
â”œâ”€â”€ Makefile                        # Helfer fÃ¼r Build, AusfÃ¼hrung, Deployment
â”œâ”€â”€ go.mod
â”œâ”€â”€ go.sum
â””â”€â”€ README.md
```

---

## ğŸ§  Intelligente Datenverarbeitung

Das `processor`-Paket wendet konfigurierbare Regeln an:

```yaml
rules:
  - type: "filter"
    field: "quality_score"
    operator: "<"
    value: 0.7
    action: "drop"
  - type: "aggregate"
    field: "vibration"
    function: "avg"
    window_seconds: 60
```

UnterstÃ¼tzte Funktionen:
- **Filtern**: UngÃ¼ltige oder irrelevante Daten verwerfen
- **Aggregieren**: Durchschnitt / Summe / Min / Max Ã¼ber ein Zeitfenster
- **Anreichern**: Gateway-ID, Standort, Zeitstempel, abgeleitete Felder hinzufÃ¼gen
- **Transformieren**: Einheiten umrechnen, Formate standardisieren

---

## ğŸš§ ZukÃ¼nftige Erweiterungen

- ğŸ”® **Edge AI/ML**: TinyML-Modelle zur Anomalieerkennung ausfÃ¼hren
- ğŸ–¥ï¸ **Lokales Dashboard**: Leichtgewichtige Web-UI mit Gin oder Echo
- ğŸŒ **UnterstÃ¼tzung mehrerer Protokolle**: CoAP, HTTP oder Modbus-EingÃ¤nge hinzufÃ¼gen
- ğŸ” **Sicherheit**: TLS, mTLS, JWT-Authentifizierung fÃ¼r MQTT/Kafka
- ğŸ§¾ **OTA-Konfiguration**: Regeln dynamisch Ã¼ber MQTT-Befehle aktualisieren
- ğŸ“ˆ **Metrik-Export**: Prometheus-Endpunkt + Grafana-Dashboards

---

## ğŸ¤ Mitwirken

BeitrÃ¤ge sind **herzlich willkommen**!

Sie kÃ¶nnen helfen durch:
- âœ… HinzufÃ¼gen neuer Verarbeitungsregeln (z. B. AusreiÃŸererkennung)
- âœ… Verbesserung der Fehlerbehandlung und Beobachtbarkeit (Observability)
- âœ… HinzufÃ¼gen von Sicherheitsfunktionen (TLS, Authentifizierung)
- âœ… Schreiben von Integrationstests
- âœ… Erstellen von Docker/Podman-UnterstÃ¼tzung
- âœ… Erstellen von Deployment-Skripten (Ansible, Terraform)

ğŸ‘‰ ErÃ¶ffnen Sie ein Issue oder senden Sie eine PR!

---

## ğŸ“š Lernerfolge

Dieses Projekt vermittelt fortgeschrittene Konzepte in:
- ğŸ–¥ï¸ Parallele Programmierung mit Go (Goroutinen, Channels)
- ğŸ“¡ Ereignisgesteuerte Architekturen mit MQTT
- ğŸ’¡ Stream-Verarbeitung und Datenaggregation
- ğŸ§± Datenpersistenz auf ressourcenbeschrÃ¤nkten Edge-GerÃ¤ten
- ğŸ”„ Integration mit Kafka fÃ¼r skalierbare Datenpipelines
- ğŸ”‹ Systemresilienz-Muster (Pufferung, Wiederholungsversuche, Idempotenz)
- ğŸ› ï¸ DevOps: Logging, Monitoring, Deployment

Ideal fÃ¼r Entwickler, die auf Positionen in den Bereichen **IoT**, **Cloud-native Systeme**, **Data Engineering** oder **Edge AI** abzielen.

---

## ğŸ—ƒï¸ Lizenz

MIT-Lizenz â€“ siehe [LICENSE](LICENSE) fÃ¼r Details.
